{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intution behind the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import ollama #import the ollama library\n",
    "import gradio as gr #provides the interface for the model\n",
    "\n",
    "#document processing and retrieval\n",
    "from langchain_community.document_loaders import PyMuPDFLoader #extract text from pdf file for processing\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter #splits text into smaller chunks for better embedding and retrieval\n",
    "from langchain.vectorstores import chroma #handles storage and vector embedding using chroma\n",
    "\n",
    "#Embedding generation\n",
    "from langchain_community.embeddings import OllamaEmbeddings #converts texts into numerical vectors using Ollama's embedding model\n",
    "import re #regular expression library for text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call DeepSeek R11.5B via API\n",
    "In this snippet, we use ollama.chat() to generate a response from DeepSeek R11.5B (which is installed locally). Let’s break it down:\n",
    "\t- **Choosing the Model**: We specify “deepseek-r11.5b” using the model argument.\n",
    "\n",
    "\t- Passing User Messages: The messages parameter is a list of interactions, where each message contains:\n",
    "\n",
    "\t- role: “user” — Indicates that the message is from the user.\n",
    "\n",
    "\t- content: “Explain Newton’s second law of motion” — The actual question asked.\n",
    "\n",
    "\t- Extracting and Printing the Response: The model generates a structured response, where the content of the reply is stored in response[\"message\"].\n",
    "\t\n",
    "\t- We print this output to display the answer.\n",
    "\n",
    "This approach allows us to interact with an LLM locally, making it a powerful way to answer queries without relying on external APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to explain the concept of orbital mechanics. Hmm, where do I start? Well, I know that orbital mechanics is all about how objects move around a central body, like planets orbiting the sun or satellites orbiting Earth. But wait, what's the big deal about that? I think it has something to do with gravity and movement.\n",
      "\n",
      "I remember hearing about Kepler's laws. There are three laws in orbital mechanics. The first one is about the square of the period being proportional to the cube of the semi-major axis. That sounds like Kepler's third law, right? So, for example, Earth orbits the sun more quickly than Venus because it's farther away. That makes sense because gravity pulls stronger when you're closer.\n",
      "\n",
      "Then there's the first law, which says that objects orbit in an ellipse. Wait, but we all know ellipses are stretched out circles. So isn't circular motion just a special case of an ellipse? Yeah, I think so. And the second law talks about areas swept by the radius being equal for equal time intervals. That's the one where the line from the sun to Earth sweeps out equal areas in equal times, which is why planets move faster when they're closer to the sun.\n",
      "\n",
      "So Keplerian motion is all about applying these three laws together to predict orbits. It explains how things like satellites orbit and how planets move around their stars. But I've heard that real-world orbital mechanics aren't perfect. Like, air resistance causes drag, which makes objects lose speed over time. There's also the problem of gravitational influence from other celestial bodies—like how Earth is affected by both the moon and the sun. That can make orbits very unstable if not accounted for.\n",
      "\n",
      "The two-body problem comes into play when we consider two objects orbiting each other. The gravitational forces between them determine their motion. But I'm not sure about the equations involved there. Maybe Newton's law of universal gravitation is what's used, which states that every particle attracts another with a force proportional to their masses and inversely proportional to the square of the distance between them.\n",
      "\n",
      "When it comes to space travel, orbital mechanics is crucial for launch times and trajectories. For example, knowing how long it takes to reach a certain orbit or where you need to aim your rocket so it arrives on time is something that relies heavily on these principles.\n",
      "\n",
      "But what about more complex orbits? I've heard of geostationary satellites. They orbit the Earth at the same rate as the Earth rotates, meaning they always point towards Earth's surface. That's pretty cool, but why does that happen? It has to do with orbital mechanics balancing gravity and centrifugal force. So if you calculate the right altitude and speed, that satellite stays in place without moving forward.\n",
      "\n",
      "I also remember about Lagrange points. These are positions where a smaller object can be placed such that it has the same gravitational influence as the two larger bodies. There are five of them: L1 between Earth and Sun, L2 opposite Earth's orbit, and maybe others? Wait, actually I think there are only one or two in each direction. The idea is to position spacecraft so they can use gravity gradients for navigation without much fuel.\n",
      "\n",
      "What about human spaceflight? It uses a lot of orbital mechanics too. If you don't compute the right burn times, your rocket might miss its target orbit due to gravitational changes from other bodies. So planning and timing are super important. That's why it takes so many days to reach Low Earth Orbit or even to the Moon.\n",
      "\n",
      "I'm also thinking about how this applies in space missions like the Apollo program. They used orbital mechanics to get spacecraft into orbit around the moon, which is a big task because they need precise calculations for where they are in their orbits and how gravity works from both Earth and the Moon. Without accurate calculations, the spacecraft wouldn't have enough time or direction to reach its destination.\n",
      "\n",
      "But then there's the challenge of predicting future gravitational influences. Like, if another planet will come close and affect a mission, you need to adjust your trajectory to keep on course. That requires real-time data analysis, which might be hard for amateur orbiters but necessary for precise missions.\n",
      "\n",
      "So in summary, orbital mechanics is all about understanding how gravity works with moving objects, applying Kepler's laws, dealing with real-world factors like air resistance and other gravitational interactions, and using this knowledge to plan space missions accurately. It's a fascinating field that ties together physics and engineering principles.\n",
      "</think>\n",
      "\n",
      "Orbital mechanics is the study of how celestial bodies such as planets, moons, and satellites move under the influence of gravity. It combines principles from physics and mathematics to predict and explain the orbits of these objects around central bodies like stars or planets.\n",
      "\n",
      "### Key Concepts:\n",
      "\n",
      "1. **Kepler's Laws**:\n",
      "   - **Third Law**: The square of the orbital period is proportional to the cube of the semi-major axis, explaining why planets orbit more quickly when farther from their star.\n",
      "   - **First and Second Laws**: These describe orbits as ellipses (including circles) and the equal area swept in time by radii, respectively.\n",
      "\n",
      "2. **Two-Body Problem**:\n",
      "   - Describes gravitational interactions between two bodies, governed by Newton's law of universal gravitation.\n",
      "\n",
      "3. **Space Travel and Orbits**:\n",
      "   - Essential for planning space missions, including launch timing, trajectory calculation, and trajectory correction to account for gravitational influences from other bodies (e.g., Earth-moon system).\n",
      "\n",
      "4. **Orbit Shapes and Balancing Forces**:\n",
      "   - Satellites like geostationary satellites maintain orbits by balancing gravitational and centrifugal forces.\n",
      "\n",
      "5. **Lagrange Points**:\n",
      "   - Positions where gravitational forces allow positioning without additional propulsion, useful for missions requiring precise navigation.\n",
      "\n",
      "6. **Human Spaceflight**:\n",
      "   - Accurate calculations are crucial to avoid missed orbits due to varying gravity from multiple bodies.\n",
      "\n",
      "7. **Applications in Missions**:\n",
      "   - Apollo program and others used orbital mechanics for spacecraft entry into orbit, leveraging precise calculations and real-time data adjustment.\n",
      "\n",
      "### Conclusion:\n",
      "Orbital mechanics is a cornerstone of space exploration, enabling the design and execution of missions like those in the Apollo program. It involves understanding gravitational principles, managing real-world perturbations, and using precise trajectory planning to achieve objectives such as reaching Low Earth Orbit or landing on Mars.\n"
     ]
    }
   ],
   "source": [
    "#call the ollama model\n",
    "response = ollama.chat(\n",
    "    model = \"deepseek-r1:1.5b\",\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"explain the concept of orbital mechanics\"},\n",
    "                ]\n",
    ")\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the PDF Document for RAG\n",
    "\n",
    "We will now create a function that pre-processes the PDF file for RAG. Below is a breakdown of its logic:\n",
    "\n",
    "- **Check if a PDF is provided**: If no file is uploaded, the function returns `None`, preventing unnecessary processing.\n",
    "- **Extract text from the PDF**: Uses `PyMuPDFLoader` to load and extract raw text from the document.\n",
    "- **Split the text into chunks**: Since LLMs process smaller text fragments better, we use `RecursiveCharacterTextSplitter`. Each chunk contains **500 characters**, with an **overlap of 100 characters** to maintain context.\n",
    "- **Generate embeddings for each chunk**: Uses `OllamaEmbeddings` with the `\"deepseek-r1:1.5b\"` model to convert text into **numerical vectors**. These embeddings allow us to find **meaning-based matches** rather than exact keyword searches.\n",
    "- **Store embeddings in a vector database**: We use `ChromaDB` to **store and organize** the generated embeddings efficiently. The data is **persisted** in `\"./chroma_db\"` to avoid recomputing embeddings every time.\n",
    "- **Create a retriever for searching the database**: The retriever acts like a **smart search engine**, enabling the chatbot to fetch the most relevant text when answering questions.\n",
    "- **Return essential components**\n",
    "    - `text_splitter` (for future text processing)\n",
    "    - `vectorstore` (holding the document embeddings)\n",
    "    - `retriever` (allowing AI-powered search over the document)\n",
    "\n",
    "## **What are embeddings?**\n",
    "Embeddings are **numerical representations of text** that capture meaning. Instead of treating words as just sequences of letters, embeddings transform them into **multi-dimensional vectors** where similar words or sentences **are placed closer together**.\n",
    "\n",
    "![image](https://miro.medium.com/v2/resize:fit:1400/1*OEmWDt4eztOcm5pr2QbxfA.png)\n",
    "_Source: https://medium.com/towards-data-science/word-embeddings-intuition-behind-the-vector-representation-of-the-words-7e4eb2410bba_\n",
    "\n",
    "### **Intuition: how do embeddings work?**\n",
    "Imagine a **map of words**:\n",
    "- Words with **similar meanings** (*cat* and *dog*) are **closer together**.\n",
    "- Words with **different meanings** (*cat* and *car*) are **farther apart**.\n",
    "- Sentences or paragraphs with similar **context** will have embeddings that are **close to each other**.\n",
    "\n",
    "This means when a user asks a question, the LLM doesn’t just look for **exact words**—it finds the **most relevant text based on meaning**, even if the wording is different.\n",
    "\n",
    "### **Why this matters?**\n",
    "This function enables a chatbot to **understand and retrieve information from PDFs efficiently**. Instead of simple keyword searches, it **finds contextually relevant information**, making AI responses **more accurate and useful**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function that process the PDF\n",
    "def process_pdf(pdf_bytes):\n",
    "    if not pdf_bytes:\n",
    "        return None, None, None\n",
    "    #load the pdf document\n",
    "    loader = PyMuPDFLoader(pdf_bytes)\n",
    "    data = loader.load()\n",
    "    #split the text into smaller chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,overlap=100)\n",
    "    chunks = text_splitter.split_document(data)\n",
    "    embeddings = OllamaEmbeddings(model=\"deepseek-r1:1.5b\")\n",
    "    vectorstore = chroma.from_document(documents = chunks, embeddings = embeddings, persist_directory = './choma_db')\n",
    "    retriever = vectorstore.as_retriever()\n",
    "\n",
    "    return text_splitter, vectorstore, retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Combining retrieved document chunks**\n",
    "Once the embeddings are retrieved, next we need to stitch these together. The `combine_docs() function merges multiple retrieved document chunks into a single string. Why do we do this?\n",
    "\n",
    "- **Provides better context** – LLMs understand structured, continuous text better than fragmented pieces.  \n",
    "- **Improves response quality** – Merging chunks helps LLMs generate more coherent and complete answers.  \n",
    "- **Preserves document flow** – Keeps information logically ordered, preventing disjointed responses.  \n",
    "- **Optimizes token usage** – Reduces redundant queries and ensures efficient use of the model’s context window.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying DeepSeek-R1 using Ollama\n",
    "\n",
    "Now, our input to the model is ready. Let’s set up DeepSeek R1 using Ollama.\n",
    "\n",
    "The `ollama_llm()` function **takes a user’s question and relevant context, formats a structured prompt, sends it to the DeepSeek-R1 model, and returns a clean generated response**.\n",
    "\n",
    "### **How it works (step-by-step)**\n",
    "- **Formats the input** – Structures the question and context for better input understanding.\n",
    "- **Calls `deepseek-r1`** – Sends the formatted prompt to generate a response.\n",
    "- **Extracts the response content** – Retrieves the AI’s answer.\n",
    "- **Cleans unnecessary text** – Removes `<think>...</think>` traces that contain model reasoning.\n",
    "- **Returns the cleaned response** – Provides a polished and readable AI answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_llm(question, context):\n",
    "    formatted_prompt = f\"question: {question} \\n\\n context: {context}\"\n",
    "    response = ollama.chat(\n",
    "        model = \"deepseek-r1:1.5b\",\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": formatted_prompt},\n",
    "        ]\n",
    "    )\n",
    "    response_content = response[\"message\"][\"content\"]\n",
    "    final_answer = re.sub(r'<think>.*?</think>', '', \n",
    "                          response_content,\n",
    "                          flags=re.DOTALL).strip()\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Build a RAG pipeline** \n",
    "\n",
    "Now we have all the required components, let’s build the RAG pipeline for our demo. We will build the `rag_chain()` function, which **retrieves relevant document chunks, formats them, and generates a response with the additional context from the retrieval step**. \n",
    "\n",
    "### **How it works**\n",
    "\n",
    "- **Retrieves relevant document chunks**: The `retriever.invoke(question)` searches for the most relevant text based on the user's question.Instead of relying solely on a language model’s memory, it **fetches factual data** from stored documents.\n",
    "- **Formats the retrieved content**: `combine_docs(retrieved_docs)` merges the document chunks into a single structured text. This ensures that DeepSeek receives a **well-organized input** for better reasoning.\n",
    "- **Generates the response**: Calls `ollama_llm(question, formatted_content)`, which:  \n",
    "    - Passes the structured input to `deepseek-r1:1.5b` for processing.  \n",
    "    - Cleans up the response (removes `<think>` tags).  \n",
    "    - Returns a polished, fact-based answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define rag_chain function for retrieval Augmented Generation\n",
    "def rag_chain(question, text_splitter, vectorstore, retriever):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_content = combine_docs(retrieved_docs)\n",
    "    return ollama_llm(question, formatted_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting it all together - Create a fuction that performs the logic expected by the chatbot\n",
    "def ask_question(pdf_bytes, question):\n",
    "    text_splitter, vectorstore, retriever = process_pdf(pdf_bytes)\n",
    "    if text_splitter is None:\n",
    "        return None\n",
    "    return rag_chain(question, text_splitter, vectorstore, retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buiding the Chat Interface with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def ask_question(pdf_file, question):\n",
    "    \"\"\"Handles PDF processing and answering user questions.\"\"\"\n",
    "    \n",
    "    if pdf_file:\n",
    "        # Read the uploaded PDF\n",
    "        pdf_bytes = pdf_file.read()\n",
    "        text_splitter, vectorstore, retriever = process_pdf(pdf_bytes)\n",
    "\n",
    "        if retriever is None:\n",
    "            return \"Error processing PDF.\"\n",
    "\n",
    "        # Retrieve relevant document content\n",
    "        docs = retriever.get_relevant_documents(question)\n",
    "        if not docs:\n",
    "            return \"No relevant information found in the document.\"\n",
    "\n",
    "        # Concatenate relevant text as response\n",
    "        response = \"\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    else:\n",
    "        # If no PDF is uploaded, provide a default response\n",
    "        response = \"No PDF uploaded. Please upload a PDF to get document-based answers.\"\n",
    "\n",
    "    return response\n",
    "\n",
    "# Define Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=ask_question,\n",
    "    inputs=[ \n",
    "        gr.File(label=\"Upload PDF (optional)\"),  # Removed `optional=True` (not needed)\n",
    "        gr.Textbox(label=\"Question\", placeholder=\"Type your question here...\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"Ask a Question About a PDF\",\n",
    "    description=\"Upload a PDF and ask a question about it. If no PDF is uploaded, you will get a default response.\",\n",
    ")\n",
    "\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
